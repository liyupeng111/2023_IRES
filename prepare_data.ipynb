{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e9f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e85495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic random seed\n",
    "DEFAULT_RANDOM_SEED = 2022\n",
    "\n",
    "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "# tensorflow random seed \n",
    "def seedTF(seed=DEFAULT_RANDOM_SEED):\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "# torch random seed\n",
    "# import torch\n",
    "# def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     torch.backends.cudnn.benchmark = False\n",
    "      \n",
    "# basic + tensorflow + torch \n",
    "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
    "    seedBasic(seed)\n",
    "    seedTF(seed)\n",
    "    # seedTorch(seed)\n",
    "\n",
    "seedEverything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999ba8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_file='data/rfam/rfam_seq_100.csv.gz'\n",
    "    label='IRES'\n",
    "    feature='Seq'\n",
    "    feature_group='ID'\n",
    "    feature_seq_len=600\n",
    "    feature_pad_end='3end'\n",
    "    channel=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9585759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168034, 9)\n",
      "(168034, 3)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CFG.input_file)\n",
    "print(df.shape)\n",
    "\n",
    "data = df[[CFG.label, CFG.feature, CFG.feature_group]]\n",
    "data = data.rename(columns={CFG.label: 'label', CFG.feature: 'seq', CFG.feature_group: 'group' })\n",
    "data = data[~data['label'].isnull()]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4211e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168034,)\n"
     ]
    }
   ],
   "source": [
    "y=data['label']\n",
    "#y=tf.keras.utils.to_categorical(y)\n",
    "g=data['group']\n",
    "#print(X.shape)\n",
    "print(y.shape)\n",
    "add_on=['A','C','G','T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "for fold in range(1,6):\n",
    "    print(fold)\n",
    "    \n",
    "    valid_split = GroupShuffleSplit(test_size=.20, n_splits=2)\n",
    "    \n",
    "    while True:\n",
    "        split = valid_split.split(data, y, groups=g)\n",
    "        train_inds, valid_inds = next(split)\n",
    "        if len(train_inds)/len(valid_inds)>3:\n",
    "            break\n",
    "    \n",
    "    data_train=data.iloc[train_inds,:]\n",
    "    data_valid=data.iloc[valid_inds,:]\n",
    "    \n",
    "    data_train_pos=data_train[data_train.label==1]\n",
    "    data_train_pos_new = data_train_pos.sample(n=data_train.shape[0], random_state=1, replace=True)\n",
    "    \n",
    "    for i in range(data_train_pos_new.shape[0]):\n",
    "        r=random.uniform(0, 1)\n",
    "        if r>0.75:\n",
    "            tmp=random.sample([-1, -2, -3], k=1)\n",
    "            data_train_pos_new.seq.iloc[i]=data_train_pos_new.seq.iloc[i][:tmp[0]]\n",
    "        if r >0.5 and r <=0.75:\n",
    "            tmp=random.sample([1, 2, 3], k=1)\n",
    "            data_train_pos_new.seq.iloc[i]=data_train_pos_new.seq.iloc[i][tmp[0]:]\n",
    "        if r >0.25 and r <=0.5:\n",
    "            tmp=''.join(np.random.choice(add_on, size=random.sample([1,2,3],k=1), replace=True))\n",
    "            data_train_pos_new.seq.iloc[i]=data_train_pos_new.seq.iloc[i] + tmp\n",
    "        else:\n",
    "            tmp=''.join(np.random.choice(add_on, size=random.sample([1,2,3],k=1), replace=True))\n",
    "            data_train_pos_new.seq.iloc[i]=tmp + data_train_pos_new.seq.iloc[i]\n",
    "\n",
    "    data_train_all = pd.concat([data_train, data_train_pos_new])\n",
    "    data_train_all = data_train_all.sample(frac=1).reset_index(drop=True)\n",
    "    data_train_all['set']='train'\n",
    "    data_valid['set']='valid'\n",
    "    data_all = pd.concat([data_train_all, data_valid])\n",
    "    data_all = data_all.reset_index(drop=True)\n",
    "    data_all['id']=str(fold)+'_'+data_all.index.astype(str)\n",
    "    data_all.to_csv('data/fold'+str(fold)+'.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
